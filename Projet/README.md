# D√©tection de Texte G√©n√©r√© par IA
### Classification Bay√©sienne & Analyse Factorielle Discriminante
**ESIEE Paris ‚Äì 2025-2026 ‚Äì E4 AP-4209**  
**Auteurs :** TORRES Diego, WU Lucas  
**Encadrant :** Badr TAJINI

---

## Table des mati√®res

1. [Vue d'ensemble](#-vue-densemble)
2. [Dataset](#-dataset)
3. [Pipeline compl√®te](#-pipeline-compl√®te)
4. [Structure du projet](#-structure-du-projet)
5. [Installation et d√©pendances](#-installation-et-d√©pendances)
6. [Utilisation](#-utilisation)
7. [R√©sultats](#-r√©sultats)
8. [M√©thodes et fondements th√©oriques](#-m√©thodes-et-fondements-th√©oriques)
9. [Limites et travaux futurs](#-limites-et-travaux-futurs)
10. [R√©f√©rences](#-r√©f√©rences)

---

## Vue d'ensemble

Ce projet impl√©mente un **syst√®me complet de d√©tection de texte g√©n√©r√© par IA**, opposant des textes humains (label `0`) √† des textes produits par des LLMs (label `1`). Il s'inscrit dans le challenge Kaggle [LLM - Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text).

L'approche repose sur une pipeline √† cinq √©tapes :

```
Texte brut
    ‚Üì
Features stylom√©triques (17 m√©triques linguistiques)
    +
TF-IDF bigrammes (332 486 termes)
    ‚Üì
SVD tronqu√©e ‚Äî k = 150 dimensions latentes
    ‚Üì
AFD (Analyse Factorielle Discriminante)  ‚Üí  1 axe LD1 (Cohen's d = 5.49)
    ‚Üì
Classification Bay√©sienne MCMC (NUTS/HMC via rstanarm)
    ‚Üì
Probabilit√©s calibr√©es P(texte IA)
```

---

## Dataset

### Source principale ‚Äî LLM-Detect (Kaggle)

| Fichier | Description | Lignes |
|---|---|---|
| `train_essays.csv` | Essais annot√©s (Kaggle officiel) | 1 378 |
| `test_essays.csv` | Essais de test (soumission Kaggle) | 3 (jeu exemple) |
| `sample_submission.csv` | Format de soumission attendu | ‚Äî |

### Source compl√©mentaire ‚Äî DRCAT

| Fichier | Description | Lignes |
|---|---|---|
| `train_drcat_01.csv` | Textes humains & IA (fold 1) | ~40 000 |
| `train_drcat_02.csv` | Textes humains & IA (fold 2) | ~40 000 |
| `train_drcat_03.csv` | Textes humains & IA (fold 3) | ~40 000 |
| `train_drcat_04.csv` | Textes humains & IA (fold 4) | ~40 000 |

**Dataset consolid√© apr√®s fusion et nettoyage :**

| Classe | Effectif | Proportion |
|---|---|---|
| Humain (0) | 116 747 | 72,6 % |
| IA (1) | 44 087 | 27,4 % |
| **Total** | **160 834** | ‚Äî |

> **Structure CSV attendue :** colonnes `text` et `generated` (0 ou 1). Les fichiers DRCAT peuvent avoir une colonne `label` qui est automatiquement renomm√©e.

### Placement des fichiers

```
projet_final/
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ llm-detect-ai-generated-text/
    ‚îÇ   ‚îî‚îÄ‚îÄ llm-detect-ai-generated-text/
    ‚îÇ       ‚îú‚îÄ‚îÄ train_essays.csv
    ‚îÇ       ‚îú‚îÄ‚îÄ test_essays.csv
    ‚îÇ       ‚îî‚îÄ‚îÄ sample_submission.csv
    ‚îú‚îÄ‚îÄ train_drcat_01.csv
    ‚îú‚îÄ‚îÄ train_drcat_02.csv
    ‚îú‚îÄ‚îÄ train_drcat_03.csv
    ‚îî‚îÄ‚îÄ train_drcat_04.csv
```

---

## Pipeline compl√®te

### √âtape 1 ‚Äî Pr√©traitement & Nettoyage

- Fusion des sources Kaggle et DRCAT
- Nettoyage du texte (retrait des doublons, suppression des entr√©es vides, filtre `nchar > 30`)
- D√©tection et correction des `NA` via `safe_texts()` (critique pour `itoken`)

### √âtape 2 ‚Äî Extraction de features stylom√©triques

17 m√©triques linguistiques extraites en parall√®le (21 c≈ìurs) avec mise en cache `.rds` :

| Feature | Description |
|---|---|
| `char_count` | Nombre total de caract√®res |
| `word_count` | Nombre total de mots |
| `sent_count` | Nombre de phrases |
| `avg_sent_len` | Longueur moyenne des phrases (mots) |
| `sent_len_sd` | **Variabilit√©** des longueurs de phrases ‚Üê discriminant fort |
| `avg_word_len` | Longueur moyenne des mots |
| `ttr` | **Type-Token Ratio** ‚Äî richesse du vocabulaire |
| `hapax_ratio` | Mots n'apparaissant qu'une seule fois |
| `flesch` | Score de lisibilit√© de Flesch (approch√©) |
| `lex_entropy` | Entropie lexicale |
| `punct_rate` | Taux de ponctuation |
| `comma_rate` | Taux de virgules |
| `upper_rate` | Taux de majuscules |
| `discourse_markers` | Connecteurs formels typiques des textes IA |
| `ai_phrases` | Expressions g√©n√©riques d√©tect√©es dans les textes IA |
| `long_word_rate` | Taux de mots longs (> 6 caract√®res) |
| `char_bigram_entropy` | **Proxy de perplexit√©** via entropie des bigrammes de caract√®res |

### √âtape 3 ‚Äî Vectorisation TF-IDF + SVD

```
TF-IDF bigrammes :  128 668 documents √ó 332 486 termes
         ‚Üì SVD tronqu√©e (irlba, k = 150)
Espace dense :      128 668 documents √ó 150 dimensions
```

- Vocabulaire unigrammes + bigrammes (`ngram = c(1L, 2L)`)
- Filtres : `term_count_min = 5`, `doc_proportion_max = 0.45`
- SVD : 54,7 % de la variance captur√©e d√®s k = 20 ; 100 % pour k = 150 (variance relative aux 150 valeurs singuli√®res calcul√©es)

### √âtape 4 ‚Äî Analyse Factorielle Discriminante (AFD)

L'AFD cherche la projection **w** maximisant le crit√®re de Fisher :

$$J(\mathbf{w}) = \frac{\mathbf{w}^\top S_B \,\mathbf{w}}{\mathbf{w}^\top S_W \,\mathbf{w}}$$

avec $S_B$ = dispersion inter-classes, $S_W$ = dispersion intra-classes.

Pour K = 2 classes, il existe **un unique axe discriminant LD1**.

**R√©sultat obtenu :**

| M√©trique | Valeur | Interpr√©tation |
|---|---|---|
| Moyenne LD1 Humain | ‚àí1.715 | Projection n√©gative |
| Moyenne LD1 IA | +4.560 | Projection positive |
| Cohen's d | **5.49** | Effet **Grand** (d > 0.8) |
| Score silhouette | **0.806** | Bonne s√©paration |

> **Justification de l'AFD lin√©aire :** La forte s√©paration lin√©aire (Cohen's d = 5.49) observ√©e sur LD1 valide le choix de l'AFD classique. Une Kernel Discriminant Analysis (KDA) apporterait une complexit√© suppl√©mentaire sans gain attendu dans ce contexte.

### √âtape 5 ‚Äî Classification Bay√©sienne MCMC

Mod√®le logistique bay√©sien :

$$\text{logit}(p_i) = \alpha + \beta \cdot \text{LD1}_i$$

| Param√®tre | Prior | Justification |
|---|---|---|
| Œ≤ | N(0, 2.5) autoscal√© | R√©gularisation Ridge bay√©sienne |
| Œ± | N(0, 5) | Prior diffus sur l'intercept |

**Algorithme :** NUTS (No-U-Turn Sampler), variante adaptative de HMC ‚Äî 4 cha√Ænes √ó 2000 it√©rations (warmup = 1000).

**Diagnostics MCMC :**
- RÃÇ max = **1.0006** (seuil < 1.01 ‚úÖ)
- n_eff ‚âà 1 600‚Äì3 200 (tr√®s satisfaisant)
- Convergence confirm√©e sur toutes les cha√Ænes

**Estimations a posteriori (IC 95 %) :**

| Param√®tre | Moyenne | SD | 2.5% | 97.5% |
|---|---|---|---|---|
| Œ± (Intercept) | ‚àí3.064 | 0.048 | ‚àí3.161 | ‚àí2.975 |
| Œ≤ (LD1) | +3.033 | 0.044 | +2.951 | +3.123 |

---

## Structure du projet

```
projet_final/
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Donn√©es brutes (non versionn√©es)
‚îÇ   ‚îú‚îÄ‚îÄ llm-detect-ai-generated-text/
‚îÇ   ‚îî‚îÄ‚îÄ train_drcat_0[1-4].csv
‚îÇ
‚îú‚îÄ‚îÄ projet_final.Rmd                   # Document principal (code + rapport)
‚îú‚îÄ‚îÄ projet_final.html                  # Rapport rendu (sortie RMarkdown)
‚îú‚îÄ‚îÄ submission.csv                     # Pr√©dictions pour soumission Kaggle
‚îÇ
‚îú‚îÄ‚îÄ cache_stylo_all.rds               # Cache features stylom√©triques (train)
‚îú‚îÄ‚îÄ cache_stylo_cv.rds                # Cache features stylom√©triques (CV)
‚îú‚îÄ‚îÄ cache_stylo_test.rds              # Cache features stylom√©triques (test)
‚îÇ
‚îî‚îÄ‚îÄ README.md                          # Ce fichier
```

---

## üîß Installation et d√©pendances

### Pr√©requis

- **R** ‚â• 4.3.0
- **RStudio** (recommand√©) ou tout √©diteur compatible RMarkdown
- M√©moire RAM recommand√©e : **‚â• 16 Go** (dataset de 160 000 textes)
- CPU multi-c≈ìurs recommand√© (extraction stylom√©trique parall√©lis√©e sur 21 c≈ìurs)

### Installation des packages

Coller dans la console R **avant** de lancer le render :

```r
install.packages(c(
  # Manipulation de donn√©es
  "readr", "dplyr", "stringr", "tidyr", "tibble",
  
  # Visualisation
  "ggplot2", "gridExtra", "scales",
  
  # NLP / Vectorisation
  "text2vec", "irlba",
  
  # Topic modeling
  "topicmodels", "slam", "tidytext",
  
  # Mod√©lisation
  "MASS", "caret",
  
  # Classification Bay√©sienne MCMC
  "rstanarm",        # Stan ‚Äî NUTS/HMC (backend principal)
  "arm",             # bayesglm ‚Äî fallback si Stan non disponible
  "bayesplot",       # Visualisation des posteriors
  
  # √âvaluation
  "pROC", "cluster"
))
```

> **Important :** `rstanarm` requiert l'installation de **Stan**. Sur Windows, il peut √™tre n√©cessaire d'installer [Rtools](https://cran.r-project.org/bin/windows/Rtools/) au pr√©alable.  
> Si `rstanarm` n'est pas disponible, le code bascule automatiquement sur `arm::bayesglm` (estimateur MAP ‚Äî fallback sans MCMC complet).

---

## Utilisation

### Lancement du rapport complet

```r
rmarkdown::render("projet_final.Rmd")
```

Ou depuis le terminal :

```powershell
& "C:\Program Files\R\R-4.5.2\bin\Rscript.exe" -e "rmarkdown::render('projet_final.Rmd')"
```

### Param√®tres cl√©s modifiables dans le Rmd

```r
USE_RSTANARM <- TRUE     # FALSE = utilise arm::bayesglm (plus rapide, moins complet)
K_SVD        <- 150      # Nombre de dimensions SVD (compromis vitesse/pr√©cision)
K_TOPICS     <- 6        # Nombre de topics LDA th√©matique
MAX_CV_N     <- 6000     # Taille du sous-√©chantillon pour la validation crois√©e
```

### Cache stylom√©trique

L'extraction stylom√©trique est **mise en cache automatiquement** (fichiers `.rds`). Pour forcer un recalcul, supprimez les fichiers `cache_stylo_*.rds` avant de relancer.

---

## R√©sultats

### M√©triques sur l'ensemble de validation (80/20 stratifi√©)

| M√©trique | Valeur |
|---|---|
| **Accuracy** | **99.34 %** |
| Precision | 99.14 % |
| Rappel (Sensibilit√©) | 98.49 % |
| Sp√©cificit√© | 99.67 % |
| **F1-score** | **98.81 %** |
| **AUC-ROC** | **0.9993** |
| **Score de Brier** | **0.0053** |
| Kappa de Cohen | 0.9836 |
| Seuil optimal F1 | 0.43 |

### Validation crois√©e 5-fold stratifi√©e

| Fold | AUC | Brier | Accuracy |
|---|---|---|---|
| 1 | 0.9979 | 0.0119 | 98.67 % |
| 2 | 0.9968 | 0.0091 | 99.08 % |
| 3 | 0.9991 | 0.0080 | 99.00 % |
| 4 | 0.9990 | 0.0111 | 98.25 % |
| 5 | 0.9973 | 0.0155 | 98.08 % |
| **Moyenne** | **0.9980 ¬± 0.0010** | **0.0111 ¬± 0.0029** | **98.62 % ¬± 0.44 %** |

### S√©paration AFD

```
Classe Humain : LD1 = ‚àí1.715  (œÉ = 0.792)
Classe IA     : LD1 = +4.560  (œÉ = 1.410)
Cohen's d     : 5.49  ‚Üí  Effet Grand
Score silhouette : 0.806  ‚Üí  Bonne s√©paration
```

### Topics LDA (k = 6, Gibbs, sous-√©chantillon 5 000 docs)

| Topic | Th√®me identifi√© | Mots cl√©s |
|---|---|---|
| Topic 1 | √âducation | students, school, learning, classes |
| Topic 2 | Transport / Vote | car, driving, Electoral, vote |
| Topic 3 | Conseil / Aide | how, could, know, someone, better |
| Topic 4 | Opinion personnelle | we, think, want, good, my |
| Topic 5 | Sciences / Espace | Venus, face, author, is_a |
| Topic 6 | Argumentation | may, important, can_be, lead |

---

## M√©thodes et fondements th√©oriques

### Th√©or√®me de Bayes

$$P(\boldsymbol{\theta} \mid \mathcal{D}) \propto P(\mathcal{D} \mid \boldsymbol{\theta}) \cdot P(\boldsymbol{\theta})$$

Le mod√®le logistique bay√©sien pr√©dit la probabilit√© qu'un texte soit g√©n√©r√© par IA. L'inf√©rence compl√®te via MCMC fournit des **distributions a posteriori** sur les param√®tres, pas simplement des estimations ponctuelles.

### Crit√®re de Fisher (AFD)

$$J(\mathbf{w}) = \frac{\mathbf{w}^\top S_B \,\mathbf{w}}{\mathbf{w}^\top S_W \,\mathbf{w}}$$

R√©solu comme un probl√®me aux valeurs propres g√©n√©ralis√© $S_W^{-1} S_B \,\mathbf{w} = \lambda\,\mathbf{w}$.

### Pourquoi SVD avant AFD ?

La matrice TF-IDF brute est **creuse** et de dimension >> 10 000 colonnes, rendant l'inversion de $S_W$ num√©riquement instable. La SVD vers k = 150 dimensions denses (1) stabilise le calcul, (2) √©limine le bruit lexical, (3) approche la normalit√© multivari√©e requise par l'AFD.

### No-U-Turn Sampler (NUTS)

Variante adaptative de HMC (Hamiltonian Monte Carlo) qui explore l'espace a posteriori bien plus efficacement que Metropolis-Hastings classique, √©vitant les random walks et le r√©glage manuel du pas d'int√©gration.

---

## Limites et travaux futurs

### Limites identifi√©es

- **Performances √©lev√©es ‚Äî interpr√©tation prudente :** Les textes IA du dataset LLM-Detect pr√©sentent des patterns stylistiques tr√®s distincts. Une validation par groupes (par source ou prompt) permettrait de d√©tecter un √©ventuel leakage contextuel li√© √† la structure du dataset.
- **Jeu de test r√©duit :** Le fichier `test_essays.csv` officiel Kaggle ne contient que 3 exemples ‚Äî la pipeline de soumission est fonctionnelle quelle que soit la taille r√©elle du jeu de test.
- **Absence de perplexit√© r√©elle :** La feature `char_bigram_entropy` est un proxy ; une vraie perplexit√© GPT-2 (via `reticulate`) serait plus discriminante.

### Travaux futurs

| Piste | B√©n√©fice attendu |
|---|---|
| Perplexit√© GPT-2 via `reticulate` | Feature tr√®s discriminante document√©e dans la litt√©rature |
| BERT / sentence embeddings | Remplacement du TF-IDF par des repr√©sentations contextuelles |
| Kernel Discriminant Analysis (KDA) | Capturer d'√©ventuelles non-lin√©arit√©s inter-classes |
| Inf√©rence variationnelle (`algorithm = "meanfield"`) | Passage √† l'√©chelle sur tr√®s grands corpus |
| LOO-CV / WAIC via `rstanarm::loo()` | Comparaison formelle de mod√®les bay√©siens |
| Validation par groupe (leave-one-prompt-out) | √âvaluation de la robustesse hors-distribution |
| Test de Box's M | V√©rification de l'homosc√©dasticit√© (hypoth√®se AFD) |

---

## R√©f√©rences

| R√©f√©rence | Lien / Citation |
|---|---|
| **Dataset LLM-Detect** | [Kaggle ‚Äî LLM Detect AI Generated Text](https://www.kaggle.com/competitions/llm-detect-ai-generated-text) |
| **Dataset DRCAT** | Compl√©ment d'entra√Ænement avec essais humains et IA |
| **rstanarm** | Goodrich et al. (2023). *rstanarm: Bayesian applied regression modeling via Stan.* CRAN |
| **Stan / NUTS** | Carpenter et al. (2017). *Stan: A probabilistic programming language.* JOSS |
| **Fisher LDA** | Fisher, R.A. (1936). *The use of multiple measurements in taxonomic problems.* Annals of Eugenics |
| **SVD / LSA** | Deerwester et al. (1990). *Indexing by Latent Semantic Analysis.* JASIS |
| **irlba** | Baglama & Reichel (2005). *Augmented implicitly restarted Lanczos bidiagonalization methods.* SIAM |
| **text2vec** | Selivanov, D. (2023). *text2vec: Modern Text Mining Framework for R.* CRAN |
| **Stylom√©trie** | Stamatatos, E. (2009). *A survey of modern authorship attribution methods.* JASIS&T |
| **Score de Brier** | Brier, G.W. (1950). *Verification of forecasts expressed in terms of probability.* Monthly Weather Review |

---

## Auteurs

| Nom | Email | √âtablissement |
|---|---|---|
| TORRES Diego | ‚Äî | ESIEE Paris |
| WU Lucas | ‚Äî | ESIEE Paris |

**Encadrant :** Badr TAJINI ‚Äî ESIEE Paris  
**Cours :** AP-4209 ‚Äî E4 ‚Äî 2025-2026  
**Rapport g√©n√©r√© le :** 19/02/2026

---

*README r√©dig√© en correspondance avec le rapport `projet_final.html` et le sujet `final_project.pdf`.*
